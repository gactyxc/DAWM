{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "uNglaPz-jzuz"
      ],
      "cell_execution_strategy": "setup",
      "toc_visible": true,
      "mount_file_id": "1wPZNk2ArIr7mGx7qkcxWb8iezUa2uxLZ",
      "authorship_tag": "ABX9TyOSRoCqEPT/TVXLTGE1FNMY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.探讨多大的样本量可以代表总体"
      ],
      "metadata": {
        "id": "uNglaPz-jzuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install rasterio matplotlib"
      ],
      "metadata": {
        "id": "xK-ioBZQ0qs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import rasterio\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "serT_1LB0pJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "统计"
      ],
      "metadata": {
        "id": "8tmhcA700maE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VI_feature_file = '/content/drive/MyDrive/14SNE/VI_parameter_EVIcos1_14SNE.tif'\n",
        "with rasterio.open(VI_feature_file) as src:\n",
        "    feature_image = src.read()\n",
        "\n",
        "# 计算总体的均值和方差\n",
        "true_mean = np.mean(feature_image)\n",
        "true_std = np.std(feature_image)\n",
        "print('***** total statistics *****')\n",
        "print('image size information:',feature_image.shape)\n",
        "print('total mean:',true_mean,'total std:',true_std)\n",
        "\n",
        "# 逐步增加样本比例，并计算均值和方差\n",
        "sample_means = []\n",
        "sample_stds = []\n",
        "sample_sizes = np.logspace(1, 8, num=100, base=10).astype(int)  # 确保最后一次抽样覆盖整个数据集\n",
        "print('***** different sample ratio statistics *****')\n",
        "for size in sample_sizes:\n",
        "    # 从总体数据中无放回随机抽样\n",
        "    sample = np.random.choice(feature_image.flatten(), size, replace=False)\n",
        "    sample_means.append(np.mean(sample))\n",
        "    sample_stds.append(np.std(sample))\n",
        "    print(f'sample size: {size}, sample mean: {np.mean(sample)}, sample std: {np.std(sample)}')\n",
        "np.save('sample_means.npy', sample_means)\n",
        "np.save('sample_stds.npy', sample_stds)\n",
        "np.save('true_mean.npy', true_mean)\n",
        "np.save('true_std.npy', true_std)\n"
      ],
      "metadata": {
        "id": "5ZuEsEY7j3Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "绘图"
      ],
      "metadata": {
        "id": "jIazIEoN0YMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "sample_sizes = np.logspace(1, 8, num=100, base=10).astype(int)\n",
        "sample_means = np.load('sample_means.npy')\n",
        "sample_stds = np.load('sample_stds.npy')\n",
        "true_mean = np.mean(feature_image)\n",
        "true_std = np.std(feature_image)\n",
        "# 创建一个图像，包含均值和方差\n",
        "plt.figure(figsize=(4, 3))\n",
        "\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.size'] = 8\n",
        "\n",
        "# 绘制样本均值和标准差\n",
        "plt.plot(sample_sizes, sample_means, linestyle='--', label='Sample Means',color='green',linewidth=1)\n",
        "plt.plot(sample_sizes, sample_stds, linestyle='--', label='Sample Std Dev', color='orange',linewidth=1)\n",
        "\n",
        "# 添加横轴为对数刻度\n",
        "plt.xscale('log')\n",
        "\n",
        "# 设置横轴刻度为 10 的幂次，并格式化为 10^n 形式\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(ticker.LogLocator(base=10.0))\n",
        "ax.xaxis.set_minor_locator(ticker.NullLocator())\n",
        "ax.xaxis.set_major_formatter(ticker.LogFormatterExponent(base=10.0))\n",
        "\n",
        "# 添加标签和图例\n",
        "plt.xlabel('Sample Size / 10^')\n",
        "plt.ylabel('EVI paramater Value / 10^-3')\n",
        "plt.legend()\n",
        "\n",
        "# 添加阈值线\n",
        "plt.axvline(x=10**4, color='gray', linestyle='--', label=r'$x=10^4$', linewidth=0.5)\n",
        "\n",
        "plt.savefig('sampleSize_figure.jpg', dpi=300,bbox_inches='tight')\n",
        "# 显示图像\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u4cKBzz5vdyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.置信学习去除样本标签噪声"
      ],
      "metadata": {
        "id": "TI6k3-Nh0utc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install rasterio matplotlib\n",
        "!pip install cleanlab scikit-learn"
      ],
      "metadata": {
        "id": "XUIIG6AW1HAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from cleanlab.classification import CleanLearning\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "dGhgHEee1Lw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 读取CSV文件，保留FID列，提取CDL标签和特征\n",
        "feature_file = '/content/drive/MyDrive/14SNE/feature_14SNE.csv'\n",
        "feature_df = pd.read_csv(feature_file)\n",
        "\n",
        "# 保留 FID 作为唯一标识符\n",
        "fid_column = feature_df['FID']\n",
        "cropland_column = feature_df['cropland']\n",
        "\n",
        "# 提取 CDL 标签，将标签24设置为1，其余为0\n",
        "cdl_labels_binary = cropland_column.apply(lambda x: 1 if x in [24, 26, 27] else 0)\n",
        "\n",
        "# 提取特征，去掉不必要的列\n",
        "features = feature_df.drop(columns=['cropland', 'FID', 'system:index', '.geo'])  # 去除标签和不需要的列\n",
        "\n",
        "# 2. 初始化置信学习模型和随机森林分类器\n",
        "rf_classifier = RandomForestClassifier()\n",
        "cl = CleanLearning(clf=rf_classifier)\n",
        "\n",
        "# 3. 定义迭代停止条件\n",
        "noise_threshold = 50  # 噪声点变化阈值\n",
        "max_iterations = 20  # 最大迭代次数\n",
        "previous_noise_count = np.inf  # 上一次迭代的噪声点数初始化为无穷大\n",
        "iteration = 0  # 迭代计数器\n",
        "\n",
        "# 4. 开始置信学习迭代\n",
        "previous_labels = cdl_labels_binary\n",
        "for iteration in range(max_iterations):\n",
        "    # 执行置信学习\n",
        "    cl.fit(features, previous_labels)\n",
        "\n",
        "    # 获取噪声点索引\n",
        "    label_issues = cl.find_label_issues(X=features, labels=previous_labels)\n",
        "    print('label_issues information:')\n",
        "    print(label_issues.head())\n",
        "    noise_indices = np.where(label_issues.is_label_issue)[0]  # 获取噪声样本的索引\n",
        "    current_noise_count = len(noise_indices)\n",
        "\n",
        "    print(f\"Iteration {iteration + 1}: Noise points = {current_noise_count}\")\n",
        "\n",
        "    # 更新上一次的噪声点数量\n",
        "    previous_labels = label_issues.predicted_label\n",
        "\n",
        "    # 判断停止条件：如果两次迭代中的噪声点变化小于阈值，则停止\n",
        "    if current_noise_count < noise_threshold:\n",
        "        print(f\"Stopped at iteration {iteration + 1}: Noise change < {noise_threshold}\")\n",
        "        break\n",
        "\n",
        "# 5. 创建噪声标记列，1表示被认为是噪声的样本，0表示非噪声样本\n",
        "is_noise = np.where(previous_labels != cdl_labels_binary, 1, 0)   # 将噪声样本标记为1\n",
        "\n",
        "# 6. 合并 FID、清洗后的置信标签和噪声标记\n",
        "result_df = pd.DataFrame({\n",
        "    'FID': fid_column,  # 原始唯一标识符\n",
        "    'cropland': cropland_column,\n",
        "    'CDL_Label': cdl_labels_binary,  # 原始CDL标签\n",
        "    'Confident_Label': previous_labels,  # 清洗后的置信标签\n",
        "    'Is_Noise': is_noise  # 噪声标记，1表示噪声，0表示非噪声\n",
        "})\n",
        "\n",
        "# 7. 输出结果，供后续操作\n",
        "print(result_df.head())  # 查看结果前几行\n",
        "result_df.to_csv('/content/drive/MyDrive/14SNE/cleaned_labels_14SNE.csv', index=False)  # 将结果保存为新的CSV文件"
      ],
      "metadata": {
        "id": "eQus4ip4pP4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.绘制t-SNE展示置信学习效果"
      ],
      "metadata": {
        "id": "TLzUVI4C8Lhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.colors import ListedColormap\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "6KFVcYaD3pOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 读取CSV文件\n",
        "feature_file = '/content/drive/MyDrive/14SNE/feature_14SNE.csv'\n",
        "feature_df = pd.read_csv(feature_file)\n",
        "features = feature_df.drop(columns=['cropland', 'FID', 'system:index', '.geo'])\n",
        "\n",
        "result_file = '/content/drive/MyDrive/14SNE/cleaned_labels_14SNE.csv'\n",
        "result_df = pd.read_csv(result_file)\n",
        "cdl_labels_binary = result_df['CDL_Label']\n",
        "previous_labels = result_df['Confident_Label']\n",
        "is_noise = result_df['Is_Noise']\n",
        "\n",
        "# 1. 执行 t-SNE 映射到三维空间\n",
        "features_EVI = features[['constant_EVI','cos_1_EVI','cos_2_EVI','cos_3_EVI','sin_1_EVI','sin_2_EVI','sin_3_EVI']]\n",
        "\n",
        "tsne = TSNE(n_components=3, random_state=42)\n",
        "features_3d = tsne.fit_transform(features_EVI)\n",
        "\n",
        "# 2. 创建一个包含原始标签和置信标签的 DataFrame\n",
        "tsne_df = pd.DataFrame({\n",
        "    'X': features_3d[:, 0],  # t-SNE 映射到三维的X轴坐标\n",
        "    'Y': features_3d[:, 1],  # t-SNE 映射到三维的Y轴坐标\n",
        "    'Z': features_3d[:, 2],  # t-SNE 映射到三维的Z轴坐标\n",
        "    'Original_Label': cdl_labels_binary,  # 原始标签\n",
        "    'Confident_Label': previous_labels,  # 经过置信学习后的标签\n",
        "    'Is_Noise': is_noise  # 噪声标记\n",
        "})\n",
        "np.save('tsne_df.npy', tsne_df)\n"
      ],
      "metadata": {
        "id": "l250yyhD8VZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. 绘制 t-SNE 三维图，分别展示原始标签和置信标签的效果\n",
        "fig = plt.figure(figsize=(8, 3.5))\n",
        "\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.size'] = 8\n",
        "\n",
        "custom_cmap = ListedColormap(['green', 'orange'])\n",
        "# 子图1: 原始标签的 t-SNE 三维图\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "scatter1 = ax1.scatter(tsne_df2['X'], tsne_df2['Y'], tsne_df2['Z'], c=tsne_df['Original_Label'], cmap=custom_cmap, s=2)\n",
        "ax1.set_title(' t-SNE without using CL',pad=-1)\n",
        "ax1.set_xlabel('t-SNE 1', labelpad=-5)\n",
        "ax1.set_ylabel('t-SNE 2', labelpad=-5)\n",
        "ax1.set_zlabel('t-SNE 3', labelpad=-8)\n",
        "ax1.view_init(elev=30, azim=30)  # 旋转三维图，使角度更好看\n",
        "\n",
        "ax1.tick_params(axis='x', pad=-3.5)  # X 轴\n",
        "ax1.tick_params(axis='y', pad=-2)  # Y 轴\n",
        "ax1.tick_params(axis='z', pad=-2)  # Z 轴\n",
        "\n",
        "# 子图2: 清洗后的置信标签的 t-SNE 三维图\n",
        "ax2 = fig.add_subplot(122, projection='3d')\n",
        "scatter2 = ax2.scatter(tsne_df2['X'], tsne_df2['Y'], tsne_df2['Z'], c=tsne_df['Confident_Label'], cmap=custom_cmap, s=2)\n",
        "ax2.set_title('t-SNE using CL',pad=0)\n",
        "ax2.set_xlabel('t-SNE 1', labelpad=-5)\n",
        "ax2.set_ylabel('t-SNE 2', labelpad=-5)\n",
        "ax2.set_zlabel('t-SNE 3', labelpad=-8)\n",
        "ax2.view_init(elev=30, azim=30)  # 旋转三维图，使角度更好看\n",
        "\n",
        "ax2.tick_params(axis='x', pad=-3.5)  # X 轴\n",
        "ax2.tick_params(axis='y', pad=-2)  # Y 轴\n",
        "ax2.tick_params(axis='z', pad=-2)  # Z 轴\n",
        "\n",
        "plt.subplots_adjust(left=0.5, wspace=0.3)\n",
        "\n",
        "# 显示图像\n",
        "plt.tight_layout()\n",
        "plt.savefig('CL_tSNE.jpg', dpi=300,bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tApQwcljVwxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.样本重聚类，同时获取参考物候曲线"
      ],
      "metadata": {
        "id": "C1epCEwM2-v2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "wLNRU50e3SxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 读取CSV文件\n",
        "feature_file = '/content/drive/MyDrive/14SNE/feature_14SNE.csv'\n",
        "feature_df = pd.read_csv(feature_file)\n",
        "\n",
        "cdl_labels = feature_df['cropland']\n",
        "\n",
        "result_file = '/content/drive/MyDrive/14SNE/cleaned_labels_14SNE.csv'\n",
        "result_df = pd.read_csv(result_file)\n",
        "result_df['cropland'] = cdl_labels\n",
        "\n",
        "feature_EVI_name = ['constant_EVI','cos_1_EVI','cos_2_EVI','cos_3_EVI','sin_1_EVI','sin_2_EVI','sin_3_EVI']\n",
        "feature_RE1_name = ['constant_RE1','cos_1_RE1','cos_2_RE1','cos_3_RE1','sin_1_RE1','sin_2_RE1','sin_3_RE1']\n",
        "feature_LSWI_name = ['constant_LSWI','cos_1_LSWI','cos_2_LSWI','cos_3_LSWI','sin_1_LSWI','sin_2_LSWI','sin_3_LSWI']\n",
        "VI_names = feature_EVI_name\n",
        "features_EVI = feature_df[feature_EVI_name]\n",
        "features_VI = feature_df[feature_LSWI_name]\n",
        "\n",
        "# 修改 121 122 123 111 类别的Is noise属性为 false\n",
        "result_df.loc[result_df['cropland'].isin([121, 122, 123, 111]), 'Is_Noise'] = False\n",
        "\n",
        "# 1. 过滤掉 `is_noise` 为 True 的样本\n",
        "filtered_data = result_df[result_df['Is_Noise'] == False]\n",
        "filtered_features = features_VI.loc[filtered_data.index]\n",
        "\n",
        "# 修改26 27类别的标签为1\n",
        "#filtered_data[result_df['cropland'] == 26]['Confident_Label'] = 1\n",
        "#filtered_data[result_df['cropland'] == 27]['Confident_Label'] = 1\n",
        "\n",
        "# 标签为 0 的数据\n",
        "data_label_0 = filtered_data[filtered_data['Confident_Label'] == 0]\n",
        "features_label_0 = filtered_features.loc[data_label_0.index]\n",
        "\n",
        "# 标签为 1 的数据\n",
        "data_label_1 = filtered_data[filtered_data['Confident_Label'] == 1]\n",
        "features_label_1 = filtered_features.loc[data_label_1.index]\n",
        "\n",
        "# 2. 使用 KMeans 对不同标签的数据分别聚类\n",
        "# 对标签为 0 的样本进行聚类\n",
        "kmeans_0 = KMeans(n_clusters=5, random_state=42)\n",
        "clusters_label_0 = kmeans_0.fit_predict(features_label_0)\n",
        "\n",
        "# 对标签为 1 的样本进行聚类\n",
        "kmeans_1 = KMeans(n_clusters=1, random_state=42)\n",
        "clusters_label_1 = kmeans_1.fit_predict(features_label_1)\n",
        "\n",
        "# 3. 设置聚类标签\n",
        "# 标签为 0 的样本聚类结果分别为 10、20、30\n",
        "cluster_labels_0 = (clusters_label_0 + 1) * 10\n",
        "\n",
        "# 标签为 1 的样本聚类结果分别为 11、21、31\n",
        "cluster_labels_1 = (clusters_label_1 + 1) * 10 + 1\n",
        "\n",
        "# 4. 将聚类结果分别赋值给原数据的聚类列\n",
        "data_label_0['Cluster'] = cluster_labels_0\n",
        "data_label_1['Cluster'] = cluster_labels_1\n",
        "\n",
        "# 5. 合并聚类结果\n",
        "clustered_data = pd.concat([data_label_0, data_label_1])\n",
        "\n",
        "# 6. 将聚类结果与原始数据合并\n",
        "# 对于 is_noise == True 的样本，将 Cluster 设置为 NaN\n",
        "result_df['Cluster'] = np.nan  # 初始化聚类列\n",
        "\n",
        "# 根据 index 更新聚类结果\n",
        "result_df.loc[clustered_data.index, 'Cluster'] = clustered_data['Cluster']\n",
        "\n",
        "# 7. 最终结果：包含 FID，CDL_Label，Confident_Label，和聚类结果\n",
        "final_result = result_df[['FID', 'cropland','CDL_Label', 'Confident_Label', 'Cluster']]\n",
        "\n",
        "# 如果需要，可以将结果导出\n",
        "final_result.to_csv('/content/drive/MyDrive/14SNE/clustered_labels_14SNE_V2.csv', index=False)\n"
      ],
      "metadata": {
        "id": "M4h1eHu24CL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.绘制不同聚类的EVI曲线示意图"
      ],
      "metadata": {
        "id": "_HqS9DSt3MLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "# 定义特征名\n",
        "feature_EVI_name = ['constant_EVI','cos_1_EVI','cos_2_EVI','cos_3_EVI','sin_1_EVI','sin_2_EVI','sin_3_EVI']\n",
        "\n",
        "# 定义颜色映射\n",
        "cmap_label_0 = cm.Greens  # 绿色渐变\n",
        "cmap_label_1 = cm.Oranges  # 橙色渐变\n",
        "\n",
        "# 定义时间序列的 x 轴范围 (比如从 0 到 2π)\n",
        "x_values = np.linspace(241, 611, 37)\n",
        "t_values = x_values * np.pi / 365\n",
        "\n",
        "# 定义谐波函数\n",
        "def harmonic_function(x, feature_row):\n",
        "    \"\"\" 构建谐波函数，基于 EVI 特征 \"\"\"\n",
        "    constant = feature_row['constant_EVI']\n",
        "    harmonic_sum = (\n",
        "        constant +\n",
        "        feature_row['cos_1_EVI'] * np.cos(x) +\n",
        "        feature_row['sin_1_EVI'] * np.sin(x) +\n",
        "        feature_row['cos_2_EVI'] * np.cos(2 * x) +\n",
        "        feature_row['sin_2_EVI'] * np.sin(2 * x) +\n",
        "        feature_row['cos_3_EVI'] * np.cos(3 * x) +\n",
        "        feature_row['sin_3_EVI'] * np.sin(3 * x)\n",
        "    )\n",
        "    return harmonic_sum\n",
        "\n",
        "# 创建一个1行2列的图像\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8.5, 3.5))\n",
        "\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.rcParams['font.size'] = 8\n",
        "\n",
        "### 自定义横纵坐标轴 ###\n",
        "xticks_values = [250, 300, 350, 400, 450, 500, 550, 600]  # 实际 x 轴数据\n",
        "xticks_labels = [250, 300, 350, 35, 85, 135, 185, 235]     # 对应的循环年度标签\n",
        "\n",
        "yticks_values = [100, 200, 300, 400, 500, 600]  # 自定义 y 轴刻度\n",
        "\n",
        "# 自定义颜色列表，子图1和子图2分别指定不同的颜色\n",
        "colors_sub1 = ['orange', 'brown', 'purple', 'green', 'blue', 'red', 'pink']  # 子图1的颜色\n",
        "colors_sub2 = ['orange', 'brown', 'purple', 'green', 'blue', 'red', 'pink']  # 子图2的颜色\n",
        "\n",
        "### 左边：不同作物的曲线图 ###\n",
        "\n",
        "crops = [24, 27, 4, 36, 37, 176, 142]\n",
        "# 定义 crops 数值与作物名称的映射\n",
        "crops_dict = {\n",
        "    24: 'Winter wheat / Ww',\n",
        "    27: 'Rye',\n",
        "    4: 'Sorghum',\n",
        "    36: 'Alfalfa',\n",
        "    37: 'Other Hay',\n",
        "    176: 'Pasture',\n",
        "    142: 'Forest'\n",
        "}\n",
        "\n",
        "# 遍历每个作物，绘制谐波曲线\n",
        "for idx, crop in enumerate(crops):\n",
        "    # 筛选属于当前作物的样本\n",
        "    cluster_data = features_EVI[result_df['cropland'] == crop]\n",
        "\n",
        "    # 初始化当前聚类的谐波曲线\n",
        "    mean_harmonic_values = np.zeros_like(t_values)\n",
        "\n",
        "    # 对每个样本计算谐波函数并取平均\n",
        "    for _, row in cluster_data[feature_EVI_name].iterrows():\n",
        "        harmonic_values = harmonic_function(t_values, row)\n",
        "        mean_harmonic_values += harmonic_values\n",
        "\n",
        "    # 平均每个聚类的谐波曲线\n",
        "    mean_harmonic_values /= len(cluster_data)\n",
        "\n",
        "    # 打印每个作物的样本数\n",
        "    print(crop, ' sample number:', len(cluster_data))\n",
        "\n",
        "    # 绘制谐波曲线\n",
        "    axes[0].plot(x_values, mean_harmonic_values, label=f'{crops_dict[crop]}', color=colors_sub1[idx],linestyle='--', alpha=0.8, linewidth=2)\n",
        "\n",
        "# 添加作物图的图例、标题和标签\n",
        "axes[0].set_title('EVI Curves for Different Crop types')\n",
        "axes[0].set_xlabel('DOY')\n",
        "axes[0].set_ylabel('EVI / 10^-2')\n",
        "\n",
        "# 设置自定义横纵坐标轴\n",
        "axes[0].set_xticks(xticks_values)\n",
        "axes[0].set_xticklabels(xticks_labels)\n",
        "axes[0].set_yticks(yticks_values)\n",
        "\n",
        "### 右边：聚类后的曲线图 ###\n",
        "\n",
        "# 获取聚类结果\n",
        "clusters = result_df['Cluster'].dropna().unique()\n",
        "clusters_dict = {\n",
        "    #21.0: 'Ww c1',\n",
        "    11.0: 'Ww c2',\n",
        "    50.0: 'Non-Ww c1',\n",
        "    30.0: 'Non-Ww c2',\n",
        "    20.0: 'Non-Ww c3',\n",
        "    40.0: 'Non-Ww c4',\n",
        "    10.0: 'Non-Ww c5'\n",
        "}\n",
        "\n",
        "# 设置聚类颜色\n",
        "color_idx_0 = 0  # 初始颜色索引，用于绿色渐变\n",
        "color_idx_1 = 0  # 初始颜色索引，用于橙色渐变\n",
        "\n",
        "# 遍历每个聚类，绘制其谐波曲线\n",
        "for idx, cluster in enumerate(clusters_dict.keys()):\n",
        "    # 筛选属于当前聚类的样本\n",
        "    cluster_data = features_EVI[result_df['Cluster'] == cluster]\n",
        "\n",
        "    # 获取该聚类的标签（0 或 1）\n",
        "    label = cluster % 10\n",
        "\n",
        "    # 选择相应的颜色映射\n",
        "    if label == 0:\n",
        "        cmap = cmap_label_0\n",
        "        color_idx = color_idx_0\n",
        "        color_idx_0 += 1  # 更新颜色索引\n",
        "    else:\n",
        "        cmap = cmap_label_1\n",
        "        color_idx = color_idx_1\n",
        "        color_idx_1 += 1  # 更新颜色索引\n",
        "\n",
        "    # 计算当前颜色\n",
        "    color = cmap((color_idx + 1) / 10)  # 假设每个标签下有 10 个聚类\n",
        "\n",
        "    # 初始化当前聚类的谐波曲线\n",
        "    #mean_harmonic_values = np.zeros_like(t_values)\n",
        "    # 定义一个列表来保存每个样本的谐波曲线\n",
        "    harmonic_values_list = []\n",
        "\n",
        "    # 对每个样本计算谐波函数并取平均\n",
        "    for _, row in cluster_data[feature_EVI_name].iterrows():\n",
        "        harmonic_values = harmonic_function(t_values, row)\n",
        "        harmonic_values_list.append(harmonic_values)  # 将每条曲线存入列表\n",
        "        #mean_harmonic_values += harmonic_values\n",
        "\n",
        "    # 平均每个聚类的谐波曲线\n",
        "    #mean_harmonic_values /= len(cluster_data)\n",
        "    harmonic_values_list = np.array(harmonic_values_list)  # 转换为 NumPy 数组\n",
        "    mean_harmonic_values = np.median(harmonic_values_list, axis=0)  # 计算中值\n",
        "\n",
        "    # 绘制聚类的平均谐波曲线\n",
        "    axes[1].plot(x_values, mean_harmonic_values, label=f'{clusters_dict[cluster]}', color=colors_sub2[idx],linestyle='--', alpha=0.8, linewidth=2)\n",
        "\n",
        "# 添加聚类图的图例、标题和标签\n",
        "axes[1].set_title('EVI Curves for Each Cluster using K-means')\n",
        "axes[1].set_xlabel('DOY')\n",
        "axes[1].set_ylabel('EVI / 10^-2')\n",
        "\n",
        "# 设置自定义横纵坐标轴\n",
        "axes[1].set_xticks(xticks_values)\n",
        "axes[1].set_xticklabels(xticks_labels)\n",
        "axes[1].set_yticks(yticks_values)\n",
        "\n",
        "### 设置两个图的相同纵轴范围 ###\n",
        "axes[0].set_ylim(60, 650)  # 设置左图的纵轴范围\n",
        "axes[1].set_ylim(60, 650)  # 设置右图的纵轴范围\n",
        "\n",
        "# 获取图例信息\n",
        "handles_1, labels_1 = axes[0].get_legend_handles_labels()  # 子图1图例\n",
        "handles_2, labels_2 = axes[1].get_legend_handles_labels()  # 子图2图例\n",
        "\n",
        "# 第一列：设置子图1的图例\n",
        "fig.legend(handles_1, labels_1, loc='lower center', ncol=3, bbox_to_anchor=(0.281, 0.754), frameon=False)\n",
        "\n",
        "# 第二列：设置子图2的图例\n",
        "fig.legend(handles_2, labels_2, loc='lower center', ncol=3, bbox_to_anchor=(0.775, 0.754), frameon=False)\n",
        "\n",
        "# 调整布局，确保图例和图像不重叠\n",
        "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
        "\n",
        "plt.savefig('clustering impect visialization.jpg', dpi=300,bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "q6G2S3v8Ea8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "\n",
        "# 假设 result_df 包含 'FID', 'Confident_Label', 'Cluster' 和 EVI 特征\n",
        "# 特征名列表\n",
        "feature_EVI_name = ['constant_EVI','cos_1_EVI','cos_2_EVI','cos_3_EVI','sin_1_EVI','sin_2_EVI','sin_3_EVI']\n",
        "\n",
        "# 提取需要的 EVI 特征列\n",
        "features_EVI = feature_df[feature_EVI_name]\n",
        "\n",
        "# 获取聚类结果\n",
        "clusters = result_df['Cluster'].unique()\n",
        "\n",
        "\n",
        "# 定义颜色映射\n",
        "cmap_label_0 = cm.Greens  # 蓝色渐变\n",
        "cmap_label_1 = cm.Oranges   # 红色渐变\n",
        "\n",
        "# 构建谐波函数\n",
        "def harmonic_function(x, feature_row):\n",
        "    \"\"\" 构建谐波函数，基于 EVI 特征 \"\"\"\n",
        "    constant = feature_row['constant_EVI']\n",
        "    harmonic_sum = (\n",
        "        constant +\n",
        "        feature_row['cos_1_EVI'] * np.cos(x) +\n",
        "        feature_row['sin_1_EVI'] * np.sin(x) +\n",
        "        feature_row['cos_2_EVI'] * np.cos(2 * x) +\n",
        "        feature_row['sin_2_EVI'] * np.sin(2 * x) +\n",
        "        feature_row['cos_3_EVI'] * np.cos(3 * x) +\n",
        "        feature_row['sin_3_EVI'] * np.sin(3 * x)\n",
        "    )\n",
        "    return harmonic_sum\n",
        "\n",
        "# 定义时间序列的 x 轴范围 (比如从 0 到 2π)\n",
        "x_values = np.linspace(241, 611, 37)\n",
        "t_values = x_values*np.pi/365\n",
        "\n",
        "# 设置聚类颜色\n",
        "color_idx_0 = 0  # 初始颜色索引，用于蓝色渐变\n",
        "color_idx_1 = 0  # 初始颜色索引，用于红色渐变\n",
        "\n",
        "# 遍历每个聚类，绘制其谐波曲线\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for cluster in clusters:\n",
        "    # 筛选属于当前聚类的样本\n",
        "    cluster_data = features_EVI[result_df['Cluster'] == cluster]\n",
        "\n",
        "    # 获取该聚类的标签（0 或 1）\n",
        "    label = cluster % 10\n",
        "\n",
        "    # 选择相应的颜色映射\n",
        "    if label == 0:\n",
        "        cmap = cmap_label_0\n",
        "        color_idx = color_idx_0\n",
        "        color_idx_0 += 1  # 更新颜色索引\n",
        "    else:\n",
        "        cmap = cmap_label_1\n",
        "        color_idx = color_idx_1\n",
        "        color_idx_1 += 1  # 更新颜色索引\n",
        "\n",
        "    # 计算当前颜色\n",
        "    color = cmap((color_idx + 1) / 10)  # 假设每个标签下有3个聚类\n",
        "\n",
        "    # 初始化当前聚类的谐波曲线\n",
        "    mean_harmonic_values = np.zeros_like(t_values)\n",
        "\n",
        "    # 对每个样本计算谐波函数并取平均\n",
        "    for _, row in cluster_data[feature_EVI_name].iterrows():\n",
        "        harmonic_values = harmonic_function(t_values, row)\n",
        "        mean_harmonic_values += harmonic_values\n",
        "\n",
        "    # 平均每个聚类的谐波曲线\n",
        "    mean_harmonic_values /= len(cluster_data)\n",
        "\n",
        "    mean_params = cluster_data[feature_EVI_name].mean()\n",
        "    mean_harmonic_values = harmonic_function(t_values, mean_params)\n",
        "\n",
        "    # 绘制聚类的平均谐波曲线\n",
        "    plt.plot(x_values, mean_harmonic_values, label=f'Cluster {cluster}', color=color)\n",
        "\n",
        "# 添加图例、标题和标签\n",
        "plt.title('Harmonic Curves for Each Cluster')\n",
        "plt.xlabel('Time (radians)')\n",
        "plt.ylabel('Harmonic Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U3B9S63K3T1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "crops = [24,27,176,37,142,141,36]\n",
        "\n",
        "# 遍历每个聚类，绘制其谐波曲线\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for crop in crops:\n",
        "    # 筛选属于当前聚类的样本\n",
        "    cluster_data = features_EVI[result_df['cropland'] == crop]\n",
        "\n",
        "    # 初始化当前聚类的谐波曲线\n",
        "    mean_harmonic_values = np.zeros_like(t_values)\n",
        "\n",
        "    # 对每个样本计算谐波函数并取平均\n",
        "    for _, row in cluster_data[feature_EVI_name].iterrows():\n",
        "        harmonic_values = harmonic_function(t_values, row)\n",
        "        mean_harmonic_values += harmonic_values\n",
        "\n",
        "    # 平均每个聚类的谐波曲线\n",
        "    mean_harmonic_values /= len(cluster_data)\n",
        "    print(crop,' sample number:',len(cluster_data))\n",
        "\n",
        "    # 绘制聚类的平均谐波曲线\n",
        "    plt.plot(x_values, mean_harmonic_values, label=f'Cluster {crop}')\n",
        "\n",
        "# 添加图例、标题和标签\n",
        "plt.title('Harmonic Curves for Each Cluster')\n",
        "plt.xlabel('Time (radians)')\n",
        "plt.ylabel('Harmonic Value')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CTyr17rQLa7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.绘制光谱和植被指数曲线图"
      ],
      "metadata": {
        "id": "7m9w4Sq3yL0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install rasterio matplotlib"
      ],
      "metadata": {
        "id": "nk-dd2NNyq8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import glob\n",
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Ek-VMbB_yruy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#生成谐波参数名\n",
        "def genetate_feature_names(bandname):\n",
        "    feature_names = [f'constant_{bandname}', f'cos_1_{bandname}', f'cos_2_{bandname}', f'cos_3_{bandname}', f'sin_1_{bandname}', f'sin_2_{bandname}', f'sin_3_{bandname}']\n",
        "    return feature_names\n",
        "\n",
        "# 定义谐波函数\n",
        "def harmonic_function(x, feature_row,bandname):\n",
        "    feature_name = genetate_feature_names(bandname)\n",
        "    \"\"\" 构建谐波函数，基于给定特征 \"\"\"\n",
        "    constant = feature_row[feature_name[0]]\n",
        "    harmonic_sum = (\n",
        "        constant +\n",
        "        feature_row[feature_name[1]] * np.cos(x) +\n",
        "        feature_row[feature_name[4]] * np.sin(x) +\n",
        "        feature_row[feature_name[2]] * np.cos(2 * x) +\n",
        "        feature_row[feature_name[5]] * np.sin(2 * x) +\n",
        "        feature_row[feature_name[3]] * np.cos(3 * x) +\n",
        "        feature_row[feature_name[6]] * np.sin(3 * x)\n",
        "    )\n",
        "    return harmonic_sum\n",
        "\n",
        "# 绘制不同作物类型以及不同簇结果的单波段谐波曲线\n",
        "def plot_harmonic_singleBand(features,labels,bandname):\n",
        "\n",
        "    features_name = genetate_feature_names(bandname)\n",
        "    # 定义时间序列的 x 轴范围 (比如从 0 到 2π)\n",
        "    x_values = np.linspace(241, 611, 37)\n",
        "    t_values = x_values * np.pi / 365\n",
        "\n",
        "    # 创建一个1行2列的图像\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8.5, 3.5))\n",
        "\n",
        "    plt.rcParams['font.family'] = 'serif'\n",
        "    plt.rcParams['font.size'] = 8\n",
        "\n",
        "    ### 自定义横纵坐标轴 ###\n",
        "    xticks_values = [250, 300, 350, 400, 450, 500, 550, 600]  # 实际 x 轴数据\n",
        "    xticks_labels = [250, 300, 350, 35, 85, 135, 185, 235]     # 对应的循环年度标签\n",
        "\n",
        "    # 自定义y轴标签，初始化存储全局最小值和最大值的变量\n",
        "    global_min = float('inf')  # 初始化为正无穷大\n",
        "    global_max = float('-inf')  # 初始化为负无穷大\n",
        "\n",
        "    # 自定义颜色列表，子图1和子图2分别指定不同的颜色\n",
        "    colors_sub1 = ['orange', 'brown', 'purple', 'green', 'blue', 'red', 'pink']  # 子图1的颜色\n",
        "    colors_sub2 = ['orange', 'brown', 'purple', 'green', 'blue', 'red', 'pink']  # 子图2的颜色\n",
        "\n",
        "    ### 左边：不同作物的曲线图 ###\n",
        "\n",
        "    crops = [24, 27, 4, 36, 37, 176, 142]\n",
        "    # 定义 crops 数值与作物名称的映射\n",
        "    crops_dict = {\n",
        "        24: 'Winter wheat / Ww',\n",
        "        27: 'Rye',\n",
        "        4: 'Sorghum',\n",
        "        36: 'Alfalfa',\n",
        "        37: 'Other Hay',\n",
        "        176: 'Pasture',\n",
        "        142: 'Forest'\n",
        "    }\n",
        "\n",
        "    # 遍历每个作物，绘制谐波曲线\n",
        "    for idx, crop in enumerate(crops):\n",
        "        # 筛选属于当前作物的样本\n",
        "        cluster_data = features[labels['cropland'] == crop]\n",
        "\n",
        "        # 初始化当前聚类的谐波曲线\n",
        "        mean_harmonic_values = np.zeros_like(t_values)\n",
        "\n",
        "        # 对每个样本计算谐波函数并取平均\n",
        "        for _, row in cluster_data[features_name].iterrows():\n",
        "            harmonic_values = harmonic_function(t_values, row,bandname)\n",
        "            mean_harmonic_values += harmonic_values\n",
        "\n",
        "        # 平均每个聚类的谐波曲线\n",
        "        mean_harmonic_values /= len(cluster_data)\n",
        "\n",
        "        # 获取y轴标签范围\n",
        "        current_min = mean_harmonic_values.min()\n",
        "        current_max = mean_harmonic_values.max()\n",
        "        # 更新全局最小值和最大值\n",
        "        if current_min < global_min:\n",
        "            global_min = current_min\n",
        "        if current_max > global_max:\n",
        "            global_max = current_max\n",
        "\n",
        "        # 打印每个作物的样本数\n",
        "        print(crop, ' sample number:', len(cluster_data))\n",
        "\n",
        "        # 绘制谐波曲线\n",
        "        axes[0].plot(x_values, mean_harmonic_values, label=f'{crops_dict[crop]}', color=colors_sub1[idx],linestyle='--', alpha=0.8, linewidth=2)\n",
        "\n",
        "    # 添加作物图的图例、标题和标签\n",
        "    axes[0].set_title('{} Curves for Different Crop types'.format(bandname))\n",
        "    axes[0].set_xlabel('DOY')\n",
        "    axes[0].set_ylabel('{} / 10^-2'.format(bandname))\n",
        "\n",
        "    # 动态定义y轴刻度\n",
        "    range_span = global_max - global_min + 130\n",
        "    # 计算y轴刻度间隔，大于800时刻度为200，小于800时刻度为100\n",
        "    if range_span < 800:\n",
        "        interval = 100  # 如果范围较小，使用100间隔\n",
        "    else:\n",
        "        interval = 200  # 如果范围较大，使用200间隔\n",
        "    # 生成动态的 yticks 刻度\n",
        "    yticks_values = np.arange(start=np.ceil(global_min / interval) * interval,\n",
        "                            stop=np.floor(global_max / interval) * interval + interval,\n",
        "                            step=interval)\n",
        "\n",
        "    # 设置自定义横纵坐标轴\n",
        "    axes[0].set_xticks(xticks_values)\n",
        "    axes[0].set_xticklabels(xticks_labels)\n",
        "    axes[0].set_yticks(yticks_values)\n",
        "\n",
        "    ### 右边：聚类后的曲线图 ###\n",
        "\n",
        "    # 获取聚类结果\n",
        "    clusters = result_df['Cluster'].dropna().unique()\n",
        "    clusters_dict = {\n",
        "        21.0: 'Ww c1',\n",
        "        11.0: 'Ww c2',\n",
        "        50.0: 'Non-Ww c1',\n",
        "        30.0: 'Non-Ww c2',\n",
        "        20.0: 'Non-Ww c3',\n",
        "        40.0: 'Non-Ww c4',\n",
        "        10.0: 'Non-Ww c5'\n",
        "    }\n",
        "\n",
        "    # 设置聚类颜色\n",
        "    color_idx_0 = 0  # 初始颜色索引，用于绿色渐变\n",
        "    color_idx_1 = 0  # 初始颜色索引，用于橙色渐变\n",
        "\n",
        "    # 遍历每个聚类，绘制其谐波曲线\n",
        "    for idx, cluster in enumerate(clusters_dict.keys()):\n",
        "        # 筛选属于当前聚类的样本\n",
        "        cluster_data = features[labels['Cluster'] == cluster]\n",
        "\n",
        "        # 初始化当前聚类的谐波曲线\n",
        "        mean_harmonic_values = np.zeros_like(t_values)\n",
        "        # 定义一个列表来保存每个样本的谐波曲线\n",
        "        #harmonic_values_list = []\n",
        "\n",
        "        #median_harmonic_parameters = cluster_data[features_name].median()\n",
        "        #median_harmonic_values = harmonic_function(t_values, median_harmonic_parameters,bandname)\n",
        "\n",
        "        # 对每个样本计算谐波函数并取平均\n",
        "        for _, row in cluster_data[features_name].iterrows():\n",
        "            harmonic_values = harmonic_function(t_values, row,bandname)\n",
        "            #harmonic_values_list.append(harmonic_values)  # 将每条曲线存入列表\n",
        "            mean_harmonic_values += harmonic_values\n",
        "\n",
        "        # 平均每个聚类的谐波曲线\n",
        "        mean_harmonic_values /= len(cluster_data)\n",
        "        #harmonic_values_list = np.array(harmonic_values_list)  # 转换为 NumPy 数组\n",
        "        #mean_harmonic_values = np.median(harmonic_values_list, axis=0)  # 计算中值\n",
        "\n",
        "        # 绘制聚类的平均谐波曲线\n",
        "        axes[1].plot(x_values, mean_harmonic_values, label=f'{clusters_dict[cluster]}', color=colors_sub2[idx],linestyle='--', alpha=0.8, linewidth=2)\n",
        "\n",
        "    # 添加聚类图的图例、标题和标签\n",
        "    axes[1].set_title('{} Curves for Each Cluster using K-means'.format(bandname))\n",
        "    axes[1].set_xlabel('DOY')\n",
        "    axes[1].set_ylabel('{} / 10^-2'.format(bandname))\n",
        "\n",
        "    # 设置自定义横纵坐标轴\n",
        "    axes[1].set_xticks(xticks_values)\n",
        "    axes[1].set_xticklabels(xticks_labels)\n",
        "    axes[1].set_yticks(yticks_values)\n",
        "\n",
        "    ### 设置两个图的相同纵轴范围 ###\n",
        "    axes[0].set_ylim(global_min-30, global_max+140)  # 设置左图的纵轴范围\n",
        "    axes[1].set_ylim(global_min-30, global_max+140)  # 设置右图的纵轴范围\n",
        "\n",
        "    # 获取图例信息\n",
        "    handles_1, labels_1 = axes[0].get_legend_handles_labels()  # 子图1图例\n",
        "    handles_2, labels_2 = axes[1].get_legend_handles_labels()  # 子图2图例\n",
        "\n",
        "    # 第一列：设置子图1的图例\n",
        "    fig.legend(handles_1, labels_1, loc='lower center', ncol=3, bbox_to_anchor=(0.281, 0.754), frameon=False)\n",
        "\n",
        "    # 第二列：设置子图2的图例\n",
        "    fig.legend(handles_2, labels_2, loc='lower center', ncol=3, bbox_to_anchor=(0.775, 0.754), frameon=False)\n",
        "\n",
        "    # 调整布局，确保图例和图像不重叠\n",
        "    plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
        "\n",
        "    plt.savefig('{} clustering impect visialization.jpg'.format(bandname), dpi=300,bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "GOGjHLa9-iN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VI_harmonicPara_file = '/content/drive/MyDrive/14SNE/feature_14SNE.csv'\n",
        "VI_harmonicPara_df = pd.read_csv(VI_harmonicPara_file)\n",
        "cropland_column = VI_harmonicPara_df['cropland']\n",
        "\n",
        "result_file = '/content/drive/MyDrive/14SNE/clustered_labels_14SNE.csv'\n",
        "result_df = pd.read_csv(result_file)\n",
        "result_df['cropland'] = cropland_column\n",
        "\n",
        "SR_harmonicPara_file = '/content/drive/MyDrive/14SNE/surfaceReflectance_14SNE.csv'\n",
        "SR_harmonicPara_df = pd.read_csv(SR_harmonicPara_file)\n",
        "\n",
        "SR_band = ['B', 'G', 'R', 'RE1', 'RE2', 'RE3', 'NIR', 'RE4', 'SWIR1', 'SWIR2']\n",
        "VI_band = ['EVI','LSWI','OSAVI','RVI']\n",
        "# plot\n",
        "for band in SR_band:\n",
        "    plot_harmonic_singleBand(SR_harmonicPara_df,result_df,band)\n",
        "for band in VI_band:\n",
        "    plot_harmonic_singleBand(VI_harmonicPara_df,result_df,band)\n",
        "\n"
      ],
      "metadata": {
        "id": "EEq9nqxxMCSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.生成参考曲线库"
      ],
      "metadata": {
        "id": "il-ZAj-KuoKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install rasterio matplotlib"
      ],
      "metadata": {
        "id": "x4NoUAs0u3DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import glob\n",
        "import os\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import curve_fit"
      ],
      "metadata": {
        "id": "XY95kQL-u3kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#生成谐波参数名\n",
        "def genetate_feature_names(bandname):\n",
        "    feature_names = [f'constant_{bandname}', f'cos_1_{bandname}', f'cos_2_{bandname}', f'cos_3_{bandname}', f'sin_1_{bandname}', f'sin_2_{bandname}', f'sin_3_{bandname}']\n",
        "    return feature_names\n",
        "\n",
        "# 定义谐波函数\n",
        "def harmonic_function(x, feature_row,bandname):\n",
        "    feature_name = genetate_feature_names(bandname)\n",
        "    \"\"\" 构建谐波函数，基于给定特征 \"\"\"\n",
        "    constant = feature_row[feature_name[0]]\n",
        "    harmonic_sum = (\n",
        "        constant +\n",
        "        feature_row[feature_name[1]] * np.cos(x) +\n",
        "        feature_row[feature_name[4]] * np.sin(x) +\n",
        "        feature_row[feature_name[2]] * np.cos(2 * x) +\n",
        "        feature_row[feature_name[5]] * np.sin(2 * x) +\n",
        "        feature_row[feature_name[3]] * np.cos(3 * x) +\n",
        "        feature_row[feature_name[6]] * np.sin(3 * x)\n",
        "    )\n",
        "    return harmonic_sum\n",
        "\n",
        "# 定义要拟合的谐波模型\n",
        "def harmonic_model(x, constant, cos_1, cos_2, cos_3, sin_1, sin_2, sin_3):\n",
        "    \"\"\" 拟合的谐波模型，基于谐波函数的形式 \"\"\"\n",
        "    return (\n",
        "        constant +\n",
        "        cos_1 * np.cos(x) + sin_1 * np.sin(x) +\n",
        "        cos_2 * np.cos(2 * x) + sin_2 * np.sin(2 * x) +\n",
        "        cos_3 * np.cos(3 * x) + sin_3 * np.sin(3 * x)\n",
        "    )\n",
        "\n",
        "# 获取谐波参数\n",
        "def get_harmonic_parameter(features,labels,bandname):\n",
        "    features_name = genetate_feature_names(bandname)\n",
        "    # 定义时间序列的 x 轴范围 (比如从 0 到 2π)\n",
        "    x_values = np.linspace(241, 611, 37)\n",
        "    t_values = x_values * np.pi / 365\n",
        "\n",
        "    clusters = result_df['Cluster'].dropna().unique()\n",
        "\n",
        "    all_popt = []\n",
        "\n",
        "    for cluster in clusters:\n",
        "        # 筛选属于当前聚类的样本\n",
        "        cluster_data = features[labels['Cluster'] == cluster]\n",
        "\n",
        "        # 初始化当前聚类的谐波曲线\n",
        "        mean_harmonic_values = np.zeros_like(t_values)\n",
        "        # 对每个样本计算谐波函数并取平均\n",
        "        for _, row in cluster_data[features_name].iterrows():\n",
        "            harmonic_values = harmonic_function(t_values, row,bandname)\n",
        "            mean_harmonic_values += harmonic_values\n",
        "        mean_harmonic_values /= len(cluster_data)\n",
        "\n",
        "        popt, pcov = curve_fit(harmonic_model, x_values, mean_harmonic_values)\n",
        "        all_popt.append((cluster, popt))\n",
        "    return all_popt\n",
        "\n",
        "# 导出谐波参数到csv文件\n",
        "def export_cluster_parameters_to_csv(all_bands_popt, output_file):\n",
        "    # Step 1: 获取所有波段名称\n",
        "    bands = [band for band, _ in all_bands_popt]\n",
        "\n",
        "    # Step 2: 初始化存储结果的列表（存储列名）\n",
        "    columns = ['Cluster']  # 第一列是 Cluster 名\n",
        "    for band in bands:\n",
        "        columns.extend([f'{band}_constant', f'{band}_cos1', f'{band}_cos2', f'{band}_cos3', f'{band}_sin1', f'{band}_sin2', f'{band}_sin3'])\n",
        "\n",
        "    # 存储每个 cluster 的行数据\n",
        "    result_rows = []\n",
        "\n",
        "    # Step 3: 遍历所有波段，按 cluster 聚合数据\n",
        "    # 假设 all_bands_popt 是 [(band_name, [(cluster1, popt1), (cluster2, popt2), ...]), ...] 形式的列表\n",
        "    cluster_keys = list(set([cluster for _, clusters_popt in all_bands_popt for cluster, _ in clusters_popt]))  # 获取所有 cluster 的 key\n",
        "\n",
        "    for cluster in cluster_keys:\n",
        "        row = [cluster]  # 初始化每行的第一个元素是 cluster 名\n",
        "\n",
        "        # 遍历每个波段的参数\n",
        "        for band, band_popt in all_bands_popt:\n",
        "            # 查找该 cluster 对应的 popt\n",
        "            popt = next((popt for c, popt in band_popt if c == cluster), [None] * 7)  # 如果找不到 cluster，填充 None\n",
        "\n",
        "            # 确保 popt 的参数顺序为 [constant, cos1, cos2, cos3, sin1, sin2, sin3]\n",
        "            row.extend(popt)\n",
        "\n",
        "        # 将该行数据添加到结果中\n",
        "        result_rows.append(row)\n",
        "\n",
        "    # Step 4: 将数据转换为 pandas DataFrame 并导出为 CSV\n",
        "    df = pd.DataFrame(result_rows, columns=columns)\n",
        "    df.to_csv(output_file, index=False)\n"
      ],
      "metadata": {
        "id": "ckyP6bFQu8vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VI_harmonicPara_file = '/content/drive/MyDrive/14SNE/feature_14SNE.csv'\n",
        "VI_harmonicPara_df = pd.read_csv(VI_harmonicPara_file)\n",
        "cropland_column = VI_harmonicPara_df['cropland']\n",
        "\n",
        "result_file = '/content/drive/MyDrive/14SNE/clustered_labels_14SNE_V2.csv'\n",
        "result_df = pd.read_csv(result_file)\n",
        "result_df['cropland'] = cropland_column\n",
        "\n",
        "SR_harmonicPara_file = '/content/drive/MyDrive/14SNE/surfaceReflectance_14SNE.csv'\n",
        "SR_harmonicPara_df = pd.read_csv(SR_harmonicPara_file)\n",
        "\n",
        "SR_band = ['B', 'G', 'R', 'RE1', 'RE2', 'RE3', 'NIR', 'RE4', 'SWIR1', 'SWIR2']\n",
        "VI_band = ['EVI','LSWI','OSAVI','RVI']\n",
        "# get the refer curve libiary\n",
        "result_SR_file = '/content/drive/MyDrive/14SNE/all_SRbands_cluster_parameters_V2.csv'\n",
        "result_VI_file = '/content/drive/MyDrive/14SNE/all_VIbands_cluster_parameters_V2.csv'\n",
        "\n",
        "all_SRbands_popt = []\n",
        "add_VIbands_popt = []\n",
        "for band in SR_band:\n",
        "    SR_parameter = get_harmonic_parameter(SR_harmonicPara_df,result_df,band)\n",
        "    all_SRbands_popt.append((band, SR_parameter))\n",
        "export_cluster_parameters_to_csv(all_SRbands_popt, result_SR_file)\n",
        "for band in VI_band:\n",
        "    VI_parameter = get_harmonic_parameter(VI_harmonicPara_df,result_df,band)\n",
        "    add_VIbands_popt.append((band, VI_parameter))\n",
        "export_cluster_parameters_to_csv(add_VIbands_popt, result_VI_file)"
      ],
      "metadata": {
        "id": "tHu6Jg-Ru4-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.计算目标年份随机样本与参考曲线库的相似度度量指标值\n"
      ],
      "metadata": {
        "id": "5z4OjQ_jbtDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install rasterio matplotlib\n",
        "!pip install tslearn joblib"
      ],
      "metadata": {
        "id": "V8BcgzyacCbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "from tslearn.metrics import dtw_path\n",
        "from joblib import Parallel, delayed\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import savgol_filter"
      ],
      "metadata": {
        "id": "Kjnkev91cExx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DTLS 关于dtw距离以及sad距离计算相关函数"
      ],
      "metadata": {
        "id": "CAXi5ctfgF9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#**** functions related to get refer VI curve\n",
        "# generate harmonic parameter name based on a given bandname\n",
        "def generate_parameter_names(bandname):\n",
        "    feature_names = [f'{bandname}_constant', f'{bandname}_cos1', f'{bandname}_cos2', f'{bandname}_cos3', f'{bandname}_sin1', f'{bandname}_sin2', f'{bandname}_sin3']\n",
        "    return feature_names\n",
        "\n",
        "# define the harmonic function\n",
        "def harmonic_function(x, feature_row,bandname):\n",
        "    parameter_names = generate_parameter_names(bandname)\n",
        "    \"\"\" 构建谐波函数，基于给定特征 \"\"\"\n",
        "    constant = feature_row[parameter_names[0]]\n",
        "    VI_harmonic_values = (\n",
        "        constant +\n",
        "        feature_row[parameter_names[1]] * np.cos(x) +\n",
        "        feature_row[parameter_names[4]] * np.sin(x) +\n",
        "        feature_row[parameter_names[2]] * np.cos(2 * x) +\n",
        "        feature_row[parameter_names[5]] * np.sin(2 * x) +\n",
        "        feature_row[parameter_names[3]] * np.cos(3 * x) +\n",
        "        feature_row[parameter_names[6]] * np.sin(3 * x)\n",
        "    )\n",
        "    return VI_harmonic_values\n",
        "\n",
        "#get refer vi curve of whole growing period based on the harmonic parameters\n",
        "def get_refer_VIcurve(VI_file,t_values,bandname):\n",
        "    VI_df = pd.read_csv(VI_file)\n",
        "    x_values = t_values * np.pi / 365\n",
        "    refer_VI_curve_list = VI_df.apply(lambda row: harmonic_function(x_values, row, bandname), axis=1)\n",
        "    refer_VI_curve_df = pd.DataFrame(refer_VI_curve_list.tolist(), columns=[f'Time_{int(t)}' for t in t_values])\n",
        "    refer_VI_curve_df['Cluster'] = VI_df['Cluster']\n",
        "    return refer_VI_curve_df\n",
        "\n",
        "# get the spectral reflectance curve based on the harmonic parameters and given time\n",
        "def get_refer_srCurve(refer_SRpara,SR_bandnames,time_Ts):\n",
        "    refer_SRpara = refer_SRpara.iloc[0]\n",
        "    refer_SR_curve_list = []\n",
        "    time_Ts = np.array(time_Ts)\n",
        "    x = 241 + (time_Ts-1) * 10 * np.pi / 365\n",
        "    for sr_bandname in SR_bandnames:\n",
        "        sr_value = harmonic_function(x, refer_SRpara,sr_bandname)\n",
        "        refer_SR_curve_list.append(sr_value)\n",
        "    refer_SR_curve_array = np.array(refer_SR_curve_list).T\n",
        "    return refer_SR_curve_array\n",
        "\n",
        "# get the refer curve time of given time T based on the path result of dtw\n",
        "def get_referTime(optimal_paths,time_T):\n",
        "    refer_Ts = []\n",
        "    for path in optimal_paths:\n",
        "        refer_T = None\n",
        "        for refer_index,sample_index in path:\n",
        "            if sample_index == time_T:\n",
        "                refer_T = refer_index\n",
        "                break\n",
        "        refer_Ts.append(refer_T)\n",
        "    return refer_Ts\n",
        "\n",
        "# get the spectral reflectance curve of target samples based on the given filename\n",
        "def get_target_srCurve(fileDir,fileIndex,sr_bandnames,FID_df):\n",
        "    target_sr_file = fileDir + f'/{int(fileIndex)}.csv'\n",
        "    target_sr_df = pd.read_csv(target_sr_file)\n",
        "    #target_sr_df = target_sr_df.head(10000)\n",
        "    target_sr_df = target_sr_df[target_sr_df['FID'].isin(FID_df['FID'])]\n",
        "    target_SR_curve_list = target_sr_df[sr_bandnames].values.tolist()\n",
        "    return target_SR_curve_list\n",
        "\n",
        "#*** get target VI value of given time period\n",
        "def get_target_VIs(target_features_fileDir, VI_bandname, time_T):\n",
        "    file_paths = [os.path.join(target_features_fileDir, f'{i}.csv') for i in range(1, time_T + 1)]\n",
        "    time_T_df = pd.read_csv(file_paths[-1])\n",
        "    time_T_FIDs = time_T_df['FID'].unique()\n",
        "    temp_data_list = []\n",
        "    for index, file_path in enumerate(file_paths, start=1):\n",
        "        df = pd.read_csv(file_path)\n",
        "        df = df[df['FID'].isin(time_T_FIDs)]\n",
        "        time = 241 + (index - 1) * 10\n",
        "        time_column_name = f'{VI_bandname}_{int(time)}'\n",
        "        df = df[['FID', VI_bandname]].rename(columns={VI_bandname: time_column_name})\n",
        "        temp_data_list.append(df)\n",
        "\n",
        "    combined_data = pd.concat(temp_data_list, axis=1, join='outer')\n",
        "    combined_data = combined_data.loc[:, ~combined_data.columns.duplicated()]\n",
        "\n",
        "    combined_data = combined_data[combined_data['FID'].isin(time_T_FIDs)]\n",
        "\n",
        "    # 对缺失值进行线性插值\n",
        "    vi_columns = [col for col in combined_data.columns if col.startswith(VI_bandname)]\n",
        "    combined_data[vi_columns] = combined_data[vi_columns].interpolate(method='linear', axis=1, limit_direction='both')\n",
        "\n",
        "    # # 确保数据列数足够应用 Savitzky-Golay 滤波器\n",
        "    # window_length = 5  # 滑动窗口大小\n",
        "    # polyorder = 2      # 多项式阶数\n",
        "    # if len(vi_columns) >= window_length:\n",
        "    #     # 使用填充方法而非np.pad来避免NaN，并使用savitzky-golay平滑\n",
        "    #     combined_data[vi_columns] = combined_data[vi_columns].apply(\n",
        "    #         lambda x: savgol_filter(x.fillna(method='ffill').fillna(method='bfill'), window_length, polyorder)\n",
        "    #         if x.notna().sum() >= window_length else x\n",
        "    #     )\n",
        "\n",
        "    # # 平滑后检查数据完整性，确保没有NaN\n",
        "    # combined_data[vi_columns] = combined_data[vi_columns].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    return combined_data\n",
        "\n",
        "#*** functions related of DTLS similarity calculation\n",
        "# function to compute DTW distance and path for one tme series\n",
        "def compute_dtw(reference,sample,search_radius):\n",
        "    distance, path = dtw_path(reference, sample,global_constraint='sakoe_chiba',sakoe_chiba_radius=search_radius)\n",
        "    return distance, path\n",
        "\n",
        "# function to compute SAD of the target surface reflectance at given time T and refer surface reflectance at related time refer_T\n",
        "def compute_sad(refer_SRs, target_SRs):\n",
        "    refer_SRs = np.array(refer_SRs)\n",
        "    target_SRs = np.array(target_SRs)\n",
        "    if refer_SRs.shape != target_SRs.shape:\n",
        "        raise ValueError(\"refer_SRs 和 target_SRs 的形状必须匹配！\")\n",
        "    dot_product = np.einsum('ij,ij->i', refer_SRs, target_SRs)\n",
        "    refer_magnitudes = np.linalg.norm(refer_SRs, axis=1)\n",
        "    target_magnitudes = np.linalg.norm(target_SRs, axis=1)\n",
        "    # Avoid division by zero by setting SAD to 1.0 for zero-magnitude cases\n",
        "    zero_mask = (refer_magnitudes == 0) | (target_magnitudes == 0)\n",
        "    # Calculate cosine similarity\n",
        "    cos_theta = np.divide(dot_product, refer_magnitudes * target_magnitudes, where=~zero_mask)\n",
        "    # Clamp values to the range [-1, 1] to avoid any issues with arccos\n",
        "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
        "    # Calculate the spectral angle distance in radians and normalize by pi, then scale by 10000\n",
        "    spectral_angle_distance = 2 * np.arccos(cos_theta) / np.pi\n",
        "    # Set SAD to 1.0 (or any indicator value you choose) where magnitudes are zero\n",
        "    spectral_angle_distance[zero_mask] = 1.0\n",
        "    return spectral_angle_distance*10000\n",
        "\n",
        "# DTLS method for sample similatity distance calculation for a given cluster and a given time T\n",
        "def DTLS_singleCluster(refer_curve,target_curve_df,target_features_fileDir,time_T,refer_SRpara,SR_bandnames,search_radius):\n",
        "    # convert the refer curve dataframe to array for dtw method input\n",
        "    time_columns = [col for col in refer_curve.columns if col.startswith('Time_')]\n",
        "    refer_curve_array = refer_curve.iloc[0][time_columns].values\n",
        "\n",
        "    # convert the target curve dataframe to array for dtw method input\n",
        "    vi_columns = [col for col in target_curve_df.columns if col.startswith('EVI_')]\n",
        "    samples_curve_series = target_curve_df.loc[:, vi_columns].values\n",
        "    extended_samples_curve_series = np.pad(\n",
        "        samples_curve_series,\n",
        "        pad_width=((0, 0), (search_radius, search_radius)),  # No padding on rows, padding on columns\n",
        "        mode='edge'\n",
        "    )\n",
        "\n",
        "    # Parallelize the DTW computation across multiple cores\n",
        "    num_cores = -1  # Use all available cores. You can specify a number like num_cores=4 to limit.\n",
        "    results = Parallel(n_jobs=num_cores)(delayed(compute_dtw)(refer_curve_array, sample,search_radius) for sample in extended_samples_curve_series)\n",
        "    # Extract distances and paths from the results\n",
        "    optimal_path,dtw_distance = zip(*results)\n",
        "\n",
        "     # get the target surface reflectance curve of given last time using the related sr file\n",
        "    target_lastT_srCurve = get_target_srCurve(target_features_fileDir,time_T,SR_bandnames,target_curve_df)\n",
        "\n",
        "    # get the refer surface reflectance curves of given last time using the harmonic parameters\n",
        "    relavent_target_lastT = time_T + search_radius - 1\n",
        "    refer_lastT = get_referTime(optimal_path,relavent_target_lastT)\n",
        "    refer_lastT_srCurve = get_refer_srCurve(refer_SRpara,SR_bandnames,refer_lastT)\n",
        "\n",
        "    # get the related spectral angle distance of related time period\n",
        "    spectral_angle_distance = compute_sad(refer_lastT_srCurve,target_lastT_srCurve)\n",
        "\n",
        "    DTLS_distance = dtw_distance + spectral_angle_distance\n",
        "\n",
        "    return dtw_distance,spectral_angle_distance #DTLS_distance\n",
        "\n",
        "#*** main producer of DTLS for sample similarity distance calculation for each cluster at given time time_T\n",
        "def DTLS_distance_calculate(target_features_fileDir,refer_SR_file,refer_VI_file,VI_bandname,SR_bandnames,out_fileDir,time_T,search_radius,tilname):\n",
        "    # get refer sr harmonic parameters\n",
        "    refer_SRpara_df = pd.read_csv(refer_SR_file)\n",
        "    # get refer vi curve\n",
        "    referT_indexs = np.linspace(1-search_radius, time_T+search_radius, time_T+2*search_radius)\n",
        "    referT_values = 241 + (referT_indexs-1)*10\n",
        "    refer_VI_curve_df = get_refer_VIcurve(refer_VI_file,referT_values,VI_bandname)\n",
        "    # get target vi value of each sample\n",
        "    target_VI_df = get_target_VIs(target_features_fileDir,VI_bandname,time_T)\n",
        "\n",
        "    sample_cluster_resultDF = pd.DataFrame()\n",
        "    sample_cluster_resultDF['FID'] = target_VI_df['FID']\n",
        "    sample_cluster_resultDF['EVI'] = target_VI_df[f'EVI_{int(241 + (time_T-1)*10)}']\n",
        "    clusters = refer_VI_curve_df['Cluster'].unique()\n",
        "    for cluster in clusters:\n",
        "        print('  cluster ',cluster,' labeling calculating ....')\n",
        "        # get the refer curve information and values of given cluster\n",
        "        refer_VI_curve_cluster = refer_VI_curve_df[refer_VI_curve_df['Cluster'] == cluster]\n",
        "        # get refer surface reflectance harmonic parameters of given cluster\n",
        "        refer_SRpara_cluster = refer_SRpara_df[refer_SRpara_df['Cluster'] == cluster]\n",
        "        # get the DTLS index value of given cluster\n",
        "        dtw_distance_column,sad_distance_column = DTLS_singleCluster(refer_VI_curve_cluster,target_VI_df,target_features_fileDir,time_T,refer_SRpara_cluster,SR_bandnames,search_radius)\n",
        "        # define the DTLS value column name of given cluster and add to the reslut dataframe\n",
        "        dtw_distance_columnName = f'{int(cluster)}_dtw_distance'\n",
        "        sad_distance_columnName = f'{int(cluster)}_sad_distance'\n",
        "        sample_cluster_resultDF[dtw_distance_columnName] = dtw_distance_column\n",
        "        sample_cluster_resultDF[sad_distance_columnName] = sad_distance_column\n",
        "\n",
        "    sample_cluster_resultDF['cluster label'] = sample_cluster_resultDF[[distance_columnName for distance_columnName in sample_cluster_resultDF.columns if 'distance' in distance_columnName]].idxmin(axis=1)\n",
        "    sample_cluster_resultDF['cluster label'] = sample_cluster_resultDF['cluster label'].str.replace('_distance', '', regex=False)\n",
        "    # weite the final DTLS value of each sample with each cluster to a csv file\n",
        "    sample_label_file = os.path.join(out_fileDir, f'sample_distance_{time_T}_{tilname}.csv')\n",
        "    sample_cluster_resultDF.to_csv(sample_label_file, index=False)\n"
      ],
      "metadata": {
        "id": "jb6OVokccL4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "组合不同不同维度距离，获取最终距离指标"
      ],
      "metadata": {
        "id": "Uys2sI09h4i_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DTLS_distance_combinate(Results_dir,VI_bandname,tilname,timeT_indexs):\n",
        "    sample_label_file0 = os.path.join(Results_dir, f'sample_distance_1_{tilname}.csv')\n",
        "    sample_label_df0 = pd.read_csv(sample_label_file0)\n",
        "\n",
        "    max_EVI = sample_label_df0.set_index('FID')[VI_bandname]  # 将 FID 设为索引\n",
        "    max_sad_distances = sample_label_df0.set_index('FID')[[col for col in sample_label_df0.columns if '_sad_distance' in col]].copy()\n",
        "    cluster_names = set(col.split('_')[0] for col in sample_label_df0.columns if '_dtw_distance' in col)\n",
        "\n",
        "    for time_T in timeT_indexs:\n",
        "        time_T = int(time_T)\n",
        "        sample_label_file = os.path.join(Results_dir, f'sample_distance_{time_T}_{tilname}.csv')\n",
        "        final_result_file = os.path.join(Results_dir, f'sample_label_{time_T}_{tilname}.csv')\n",
        "        distance_df = pd.read_csv(sample_label_file).set_index('FID')\n",
        "        final_distance_df = pd.DataFrame(index=distance_df.index)\n",
        "\n",
        "        EVI_cur = distance_df[VI_bandname]\n",
        "        dtw_distance_curs = distance_df[[col for col in distance_df.columns if '_dtw_distance' in col]]\n",
        "        sad_distance_curs = distance_df[[col for col in distance_df.columns if '_sad_distance' in col]]\n",
        "\n",
        "        max_EVI = max_EVI.reindex(max_EVI.index.union(distance_df.index), fill_value=-np.inf)\n",
        "        max_sad_distances = max_sad_distances.reindex(max_EVI.index)\n",
        "\n",
        "        merged_EVI = pd.concat([EVI_cur, max_EVI], axis=1, keys=['EVI_cur', 'EVI_max'])\n",
        "\n",
        "        for cluster in cluster_names:\n",
        "            sad_distance_cur = sad_distance_curs[f'{cluster}_sad_distance']\n",
        "            sad_distance_max = max_sad_distances[f'{cluster}_sad_distance']\n",
        "\n",
        "            # 更新 sad 距离：如果当前 EVI 大于最大 EVI，则用当前时相的 sad 距离，否则用最大 EVI 的 sad 距离\n",
        "            updated_sad_distance = sad_distance_cur.where(\n",
        "                (merged_EVI['EVI_cur'] > merged_EVI['EVI_max']) | merged_EVI['EVI_max'].isna(),\n",
        "                sad_distance_max\n",
        "            )\n",
        "\n",
        "            # 更新最大 EVI 和对应的 sad_distance\n",
        "            max_EVI = merged_EVI['EVI_cur'].where(merged_EVI['EVI_cur'] > merged_EVI['EVI_max'], merged_EVI['EVI_max'])\n",
        "            max_sad_distances[f'{cluster}_sad_distance'] = updated_sad_distance\n",
        "\n",
        "            # 计算 dtls 距离\n",
        "            dtw_distance = dtw_distance_curs[f'{cluster}_dtw_distance']\n",
        "            dtls_distance = dtw_distance + updated_sad_distance\n",
        "            final_distance_df[f'{cluster}_distance'] = dtls_distance\n",
        "\n",
        "        # 获取最小距离的 cluster 作为标签\n",
        "        final_distance_df['cluster label'] = final_distance_df[[col for col in final_distance_df.columns if 'distance' in col]].idxmin(axis=1)\n",
        "        final_distance_df['cluster label'] = final_distance_df['cluster label'].str.replace('_distance', '', regex=False)\n",
        "\n",
        "        # 将 FID 添加回最终结果并保存\n",
        "        final_distance_df.reset_index(inplace=True)  # 重置索引以便输出时包含 FID 列\n",
        "        final_distance_df.to_csv(final_result_file, index=False)\n",
        "        print(f'Time step {time_T} calculation done.')"
      ],
      "metadata": {
        "id": "fQeeo1WCh4KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "计算获取样点标签和CDL之间的一致性"
      ],
      "metadata": {
        "id": "4NBAPUABrJMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_finalLable_accuracyAssessment(cdl_file,target_sampleResults_dir,metrics_file,tilname,timeT_indexs,cdl_maizeLabels,cluster_maizeLabels):\n",
        "    cdl_df = pd.read_csv(cdl_file)\n",
        "    final_labels = pd.DataFrame()\n",
        "    final_labels['FID'] = cdl_df['FID']\n",
        "    final_labels['CDL_Label'] = cdl_df['cropland']\n",
        "    single_label_file = os.path.join(target_sampleResults_dir, f'single_labels_{tilname}.csv')\n",
        "    cumulated_label_file = os.path.join(target_sampleResults_dir,f'cumulative_mode_labels_{tilname}.csv')\n",
        "\n",
        "    for time in timeT_indexs:\n",
        "        time = int(time)\n",
        "        sample_label_file = os.path.join(target_sampleResults_dir, f'sample_label_{time}_{tilname}.csv')\n",
        "        sample_label_df = pd.read_csv(sample_label_file)\n",
        "        final_labels[f'{time}_Label'] = sample_label_df['cluster label']\n",
        "    final_labels.to_csv(single_label_file, index=False)\n",
        "    print(single_label_file,'write done.')\n",
        "\n",
        "    # Initialize a new DataFrame to store the mode labels\n",
        "    mode_labels = pd.DataFrame()\n",
        "    mode_labels['FID'] = final_labels['FID']\n",
        "    mode_labels['CDL_Label'] = final_labels['CDL_Label']\n",
        "\n",
        "    # Calculate cumulative mode for each time\n",
        "    for i, time in enumerate(timeT_indexs):\n",
        "        time = int(time)\n",
        "        # select columns up to the current time to calculate mode\n",
        "        cols_to_mode = [f'{int(t)}_Label' for t in timeT_indexs[:i+1]]\n",
        "\n",
        "        # Calculate mode along the rows for the selected columns\n",
        "        mode_labels[f'{time}_Mode_Label'] = final_labels[cols_to_mode].mode(axis=1)[0]\n",
        "\n",
        "    # Save the cumulative mode labels DataFrame\n",
        "    mode_labels.to_csv(cumulated_label_file, index=False)\n",
        "    print(cumulated_label_file,'write done.')\n",
        "\n",
        "    # 初始化存储精度指标的 DataFrame\n",
        "    metrics_df = pd.DataFrame(columns=['Time', '00', '01', '10', '11',\n",
        "                                        'Precision (Class 0)', 'Recall (Class 0)', 'Accuracy', 'F1-score (Class 0)', 'IoU (Class 0)',\n",
        "                                        'Precision (Class 1)', 'Recall (Class 1)', 'F1-score (Class 1)', 'IoU (Class 1)'])\n",
        "    # 计算每个时间的精度指标\n",
        "    for time in timeT_indexs:\n",
        "        time = int(time)\n",
        "        time_label_column = f'{time}_Mode_Label'\n",
        "        # Filter out rows with NaN values in the current time label column\n",
        "        valid_labels = mode_labels.dropna(subset=[time_label_column]).copy()\n",
        "        # Generate four classification categories\n",
        "        valid_labels['11'] = ((valid_labels[time_label_column].isin(cluster_maizeLabels)) &\n",
        "                              (valid_labels['CDL_Label'].isin(cdl_maizeLabels))).astype(int)\n",
        "        valid_labels['01'] = ((valid_labels[time_label_column].isin(cluster_maizeLabels)) &\n",
        "                              (~valid_labels['CDL_Label'].isin(cdl_maizeLabels))).astype(int)\n",
        "        valid_labels['10'] = ((~valid_labels[time_label_column].isin(cluster_maizeLabels)) &\n",
        "                              (valid_labels['CDL_Label'].isin(cdl_maizeLabels))).astype(int)\n",
        "        valid_labels['00'] = ((~valid_labels[time_label_column].isin(cluster_maizeLabels)) &\n",
        "                              (~valid_labels['CDL_Label'].isin(cdl_maizeLabels))).astype(int)\n",
        "        count_11 = valid_labels['11'].sum()\n",
        "        count_01 = valid_labels['01'].sum()\n",
        "        count_10 = valid_labels['10'].sum()\n",
        "        count_00 = valid_labels['00'].sum()\n",
        "\n",
        "        y_true = valid_labels['CDL_Label'].isin(cdl_maizeLabels).astype(int)\n",
        "        y_pred = valid_labels[time_label_column].isin(cluster_maizeLabels).astype(int)\n",
        "\n",
        "        # Metrics for Class 0\n",
        "        precision_0 = precision_score(y_true, y_pred, pos_label=0)\n",
        "        recall_0 = recall_score(y_true, y_pred, pos_label=0)\n",
        "        f1_score_0 = f1_score(y_true, y_pred, pos_label=0)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        iou_0 = tn / (tn + fp + fn)  # IoU for Class 0\n",
        "        # Metrics for Class 1\n",
        "        precision_1 = precision_score(y_true, y_pred, pos_label=1)\n",
        "        recall_1 = recall_score(y_true, y_pred, pos_label=1)\n",
        "        f1_score_1 = f1_score(y_true, y_pred, pos_label=1)\n",
        "        iou_1 = tp / (tp + fp + fn)  # IoU for Class 1\n",
        "        overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "        metrics_row = pd.DataFrame({\n",
        "            'Time': [time],\n",
        "            '00': [count_00],\n",
        "            '01': [count_01],\n",
        "            '10': [count_10],\n",
        "            '11': [count_11],\n",
        "            'Precision (Class 0)': [precision_0],\n",
        "            'Recall (Class 0)': [recall_0],\n",
        "            'Accuracy': [overall_accuracy],\n",
        "            'F1-score (Class 0)': [f1_score_0],\n",
        "            'IoU (Class 0)': [iou_0],\n",
        "            'Precision (Class 1)': [precision_1],\n",
        "            'Recall (Class 1)': [recall_1],\n",
        "            'F1-score (Class 1)': [f1_score_1],\n",
        "            'IoU (Class 1)': [iou_1]\n",
        "        })\n",
        "\n",
        "        metrics_df = pd.concat([metrics_df, metrics_row], ignore_index=True)\n",
        "    metrics_df.to_csv(metrics_file, index=False)\n",
        "    print(metrics_file,'write done.')\n",
        "\n"
      ],
      "metadata": {
        "id": "xKJ4Cc82rJl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "绘制标签精度时间变化曲线"
      ],
      "metadata": {
        "id": "jIN_fTL_x0Yv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracyCurve(metrics_file,tilname):\n",
        "    # Read the metrics file\n",
        "    metrics_df = pd.read_csv(metrics_file)\n",
        "\n",
        "    # Sort by time to ensure correct plotting order\n",
        "    metrics_df = metrics_df.sort_values(by='Time')\n",
        "\n",
        "    # Map Time (1-37) to a range starting from day 240, incrementing by 10 days for each step\n",
        "    mapped_days = [240 + (i - 1) * 10 for i in metrics_df['Time']]\n",
        "    metrics_df['Mapped_Days'] = mapped_days\n",
        "\n",
        "    # Set up the plot\n",
        "    plt.figure(figsize=(8, 5.2))\n",
        "\n",
        "    plt.rcParams['font.family'] = 'serif'\n",
        "    plt.rcParams['font.size'] = 8\n",
        "\n",
        "    # Plot metrics for Class 1\n",
        "    plt.plot(metrics_df['Mapped_Days'], metrics_df['Precision (Class 1)'], label='Precision (Maize)', marker='x')\n",
        "    plt.plot(metrics_df['Mapped_Days'], metrics_df['F1-score (Class 1)'], label='F1-score (Maize)', marker='x')\n",
        "\n",
        "    # Plot overall accuracy\n",
        "    plt.plot(metrics_df['Mapped_Days'], metrics_df['Accuracy'], label='Overall Accuracy', marker='o')\n",
        "\n",
        "    # Plot metrics for Class 0\n",
        "    plt.plot(metrics_df['Mapped_Days'], metrics_df['Precision (Class 0)'], label='Precision (Non-Maize)', marker='x')\n",
        "    plt.plot(metrics_df['Mapped_Days'], metrics_df['F1-score (Class 0)'], label='F1-score (Non-Maize)', marker='x')\n",
        "\n",
        "    # Add legend, title, and labels\n",
        "    plt.xlabel('Time (Days)')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Time Series of Accuracy Metrics for Maize and Non-Maize smaples')\n",
        "\n",
        "    # Define custom x-ticks from day 240 of the current year to day 240 of the next year\n",
        "    custom_ticks = np.arange(240, 240 + 370, 30)  # Generates ticks from 240 to 240 + 370, every 30 days\n",
        "    custom_labels = [tick % 365 for tick in custom_ticks]  # Convert to 0-364 scale for display\n",
        "\n",
        "    # Customize x-axis ticks and labels\n",
        "    plt.xticks(ticks=custom_ticks, labels=custom_labels, rotation=45)\n",
        "\n",
        "    # Set x-axis limits to start and end precisely at 240 and 240+370\n",
        "    plt.xlim(240, 240 + 365)\n",
        "\n",
        "    # Show legend and grid\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{tilname}_samples_accuracy.jpg', dpi=300,bbox_inches='tight')\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VFh3f83bx0Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "主函数"
      ],
      "metadata": {
        "id": "NqccfZlAgSX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_features_fileDir = '/content/drive/MyDrive/14SNE/samples_SR2023/'\n",
        "refer_SR_file = '/content/drive/MyDrive/14SNE/all_SRbands_cluster_parameters.csv'\n",
        "refer_VI_file = '/content/drive/MyDrive/14SNE/all_VIbands_cluster_parameters.csv'\n",
        "cdl_file = '/content/drive/MyDrive/14SNE/cdlTarget_samples_14SNE.csv'\n",
        "\n",
        "target_sampleResults_dir = '/content/drive/MyDrive/14SNE/target_sample_label/'\n",
        "os.makedirs(target_sampleResults_dir, exist_ok=True)\n",
        "\n",
        "tilname = '14SNE'\n",
        "metrics_file = f'/content/drive/MyDrive/{tilname}/accuracy_metrics_{tilname}.csv'\n",
        "\n",
        "VI_bandname = 'EVI'\n",
        "SR_bandnames = ['B', 'G', 'R', 'RE1', 'RE2', 'RE3', 'NIR', 'RE4', 'SWIR1', 'SWIR2']\n",
        "search_radius = 2\n",
        "\n",
        "cdl_maizeLabels = [24,27]\n",
        "cluster_maizeLabels = [11,21]\n",
        "\n",
        "timeT_indexs = np.linspace(1, 37, 37)\n",
        "for time_T in timeT_indexs:\n",
        "    time_T = int(time_T)\n",
        "    print('time ',time_T,'th labeling calculating....')\n",
        "    DTLS_distance_calculate(target_features_fileDir,refer_SR_file,refer_VI_file,VI_bandname,SR_bandnames,target_sampleResults_dir,time_T,search_radius,tilname)\n",
        "    print('time ',time_T,'th labeling finished....')\n",
        "\n",
        "DTLS_distance_combinate(target_sampleResults_dir,VI_bandname,tilname,timeT_indexs)\n",
        "get_finalLable_accuracyAssessment(cdl_file,target_sampleResults_dir,metrics_file,tilname,timeT_indexs,cdl_maizeLabels,cluster_maizeLabels)\n",
        "plot_accuracyCurve(metrics_file,tilname)"
      ],
      "metadata": {
        "id": "DtO3cMlxcNGw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}